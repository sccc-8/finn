{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9e94d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -U ipytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2a9809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "import ipytest\n",
    "\n",
    "ipytest.autoconfig()\n",
    "ipytest.config.rewrite_asserts = True\n",
    "\n",
    "__file__ = 'test_fclayer.ipynb'\n",
    "\n",
    "import numpy as np\n",
    "from onnx import TensorProto, helper\n",
    "from finn.util.visualization import showSrc, showInNetron\n",
    "\n",
    "from finn.custom_op.registry import getCustomOp\n",
    "import finn.core.onnx_exec as oxe\n",
    "import finn.custom_op.general.xnorpopcount as xp\n",
    "from finn.analysis.fpgadataflow.hls_synth_res_estimation import hls_synth_res_estimation\n",
    "from finn.core.datatype import DataType\n",
    "from finn.core.modelwrapper import ModelWrapper\n",
    "from finn.custom_op.general.multithreshold import multithreshold\n",
    "from finn.transformation.fpgadataflow.prepare_ip import PrepareIP\n",
    "from finn.transformation.fpgadataflow.prepare_cppsim import PrepareCppSim\n",
    "from finn.transformation.fpgadataflow.compile_cppsim import CompileCppSim\n",
    "from finn.transformation.fpgadataflow.hlssynth_ip import HLSSynthIP\n",
    "from finn.transformation.fpgadataflow.set_exec_mode import SetExecMode\n",
    "from finn.transformation.general import GiveReadableTensorNames, GiveUniqueNodeNames\n",
    "from finn.transformation.fpgadataflow.prepare_rtlsim import PrepareRTLSim\n",
    "from finn.util.basic import calculate_signed_dot_prod_range, gen_finn_dt_tensor\n",
    "from finn.analysis.fpgadataflow.exp_cycles_per_layer import exp_cycles_per_layer\n",
    "from finn.analysis.fpgadataflow.dataflow_performance import dataflow_performance\n",
    "from finn.analysis.fpgadataflow.res_estimation import res_estimation\n",
    "\n",
    "from finn.transformation.fpgadataflow.insert_fifo import InsertFIFO\n",
    "from finn.util.basic import pynq_part_map\n",
    "from finn.transformation.fpgadataflow.make_zynq_proj import ZynqBuild\n",
    "from finn.analysis.fpgadataflow.post_synth_res import post_synth_res\n",
    "\n",
    "build_dir = \"/workspace/finn\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dd87c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_single_fclayer_modelwrapper(W, pe, simd, wdt, idt, odt, T=None, tdt=None):\n",
    "    mw = W.shape[0]\n",
    "    mh = W.shape[1]\n",
    "    assert mh % pe == 0\n",
    "    assert mw % simd == 0\n",
    "\n",
    "    # there are two ways to implement bipolar weights and inputs for\n",
    "    # StreamingFC:\n",
    "    # - specify their datatypes as such\n",
    "    # - specify their datatypes as BINARY as use binaryXnorMode\n",
    "    if wdt == DataType.BIPOLAR and idt == DataType.BIPOLAR:\n",
    "        # we'll internally convert weights/inputs to binary and specify the\n",
    "        # datatypes as such, and also set the binaryXnorMode attribute to 1\n",
    "        export_wdt = DataType.BINARY\n",
    "        export_idt = DataType.BINARY\n",
    "        binary_xnor_mode = 1\n",
    "    else:\n",
    "        export_wdt = wdt\n",
    "        export_idt = idt\n",
    "        binary_xnor_mode = 0\n",
    "\n",
    "    inp = helper.make_tensor_value_info(\"inp\", TensorProto.FLOAT, [1, mw])\n",
    "    outp = helper.make_tensor_value_info(\"outp\", TensorProto.FLOAT, [1, mh])\n",
    "    if T is not None:\n",
    "        no_act = 0\n",
    "        node_inp_list = [\"inp\", \"weights\", \"thresh\"]\n",
    "        if odt == DataType.BIPOLAR:\n",
    "            actval = 0\n",
    "        else:\n",
    "            actval = odt.min()\n",
    "    else:\n",
    "        # no thresholds\n",
    "        node_inp_list = [\"inp\", \"weights\"]\n",
    "        actval = 0\n",
    "        no_act = 1\n",
    "    FCLayer_node = helper.make_node(\n",
    "        \"StreamingFCLayer_Batch\",\n",
    "        node_inp_list,\n",
    "        [\"outp\"],\n",
    "        domain=\"finn.custom_op.fpgadataflow\",\n",
    "        backend=\"fpgadataflow\",\n",
    "        MW=mw,\n",
    "        MH=mh,\n",
    "        SIMD=simd,\n",
    "        PE=pe,\n",
    "        inputDataType=export_idt.name,\n",
    "        weightDataType=export_wdt.name,\n",
    "        outputDataType=odt.name,\n",
    "        ActVal=actval,\n",
    "        binaryXnorMode=binary_xnor_mode,\n",
    "        noActivation=no_act,\n",
    "    )\n",
    "    graph = helper.make_graph(\n",
    "        nodes=[FCLayer_node], name=\"fclayer_graph\", inputs=[inp], outputs=[outp]\n",
    "    )\n",
    "\n",
    "    model = helper.make_model(graph, producer_name=\"fclayer-model\")\n",
    "    model = ModelWrapper(model)\n",
    "\n",
    "    model.set_tensor_datatype(\"inp\", idt)\n",
    "    model.set_tensor_datatype(\"outp\", odt)\n",
    "    model.set_tensor_datatype(\"weights\", wdt)\n",
    "    if binary_xnor_mode:\n",
    "        # convert bipolar to binary\n",
    "        model.set_initializer(\"weights\", (W + 1) / 2)\n",
    "    else:\n",
    "        model.set_initializer(\"weights\", W)\n",
    "    if T is not None:\n",
    "        model.set_tensor_datatype(\"thresh\", tdt)\n",
    "        model.set_initializer(\"thresh\", T)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07167918",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_inputs(input_tensor, idt, wdt):\n",
    "    if wdt == DataType.BIPOLAR and idt == DataType.BIPOLAR:\n",
    "        # convert bipolar to binary\n",
    "        return {\"inp\": (input_tensor + 1) / 2}\n",
    "    else:\n",
    "        return {\"inp\": input_tensor}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59620e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mem_mode: const or decoupled\n",
    "@pytest.mark.parametrize(\"mem_mode\", [\"const\"])\n",
    "# activation: None or DataType\n",
    "@pytest.mark.parametrize(\"act\", [DataType.BIPOLAR, DataType.INT2, DataType.INT4])\n",
    "# weight datatype\n",
    "@pytest.mark.parametrize(\"wdt\", [DataType.BIPOLAR, DataType.INT2, DataType.INT4])\n",
    "# input datatype\n",
    "@pytest.mark.parametrize(\"idt\", [DataType.BIPOLAR, DataType.INT2, DataType.INT4])\n",
    "# neuron folding, -1 is maximum possible\n",
    "@pytest.mark.parametrize(\"nf\", [-1, 2, 1])\n",
    "# synapse folding, -1 is maximum possible\n",
    "@pytest.mark.parametrize(\"sf\", [-1, 2, 1])\n",
    "# HLS matrix width (input features)\n",
    "@pytest.mark.parametrize(\"mw\", [8])\n",
    "# HLS matrix height (output features)\n",
    "@pytest.mark.parametrize(\"mh\", [8])\n",
    "@pytest.mark.slow\n",
    "@pytest.mark.vivado\n",
    "def test_fpgadataflow_fclayer_cppsim(mem_mode, idt, wdt, act, nf, sf, mw, mh):\n",
    "    if nf == -1:\n",
    "        nf = mh\n",
    "    if sf == -1:\n",
    "        sf = mw\n",
    "    pe = mh // nf\n",
    "    simd = mw // sf\n",
    "    assert mh % pe == 0\n",
    "    assert mw % sf == 0\n",
    "    # generate weights\n",
    "    W = gen_finn_dt_tensor(wdt, (mw, mh))\n",
    "    # generate input data\n",
    "    x = gen_finn_dt_tensor(idt, (1, mw))\n",
    "    if act is None:\n",
    "        # no activation, produce accumulators\n",
    "        T = None\n",
    "        tdt = None\n",
    "        if wdt == DataType.BIPOLAR and idt == DataType.BIPOLAR:\n",
    "            odt = DataType.UINT32\n",
    "        else:\n",
    "            odt = DataType.INT32\n",
    "    else:\n",
    "        odt = act\n",
    "        (min, max) = calculate_signed_dot_prod_range(idt, wdt, mw)\n",
    "        n_steps = act.get_num_possible_values() - 1\n",
    "        T = np.random.randint(min, max - 1, (mh, n_steps)).astype(np.float32)\n",
    "        # provide non-decreasing thresholds\n",
    "        T = np.sort(T, axis=1)\n",
    "        # generate thresholds for activation\n",
    "        if wdt == DataType.BIPOLAR and idt == DataType.BIPOLAR:\n",
    "            tdt = DataType.UINT32\n",
    "            # bias thresholds to be positive\n",
    "            T = np.ceil((T + mw) / 2)\n",
    "            assert (T >= 0).all()\n",
    "        else:\n",
    "            tdt = DataType.INT32\n",
    "    model = make_single_fclayer_modelwrapper(W, pe, simd, wdt, idt, odt, T, tdt)\n",
    "    for node in model.graph.node:\n",
    "        # lookup op_type in registry of CustomOps\n",
    "        inst = getCustomOp(node)\n",
    "        inst.set_nodeattr(\"mem_mode\", mem_mode)\n",
    "    model = model.transform(SetExecMode(\"cppsim\"))\n",
    "    model = model.transform(PrepareCppSim())\n",
    "    model = model.transform(CompileCppSim())\n",
    "    # prepare input data\n",
    "    input_dict = prepare_inputs(x, idt, wdt)\n",
    "    if wdt == DataType.BIPOLAR and idt == DataType.BIPOLAR:\n",
    "        # convert inputs to binary and use xnorpopcountmatmul\n",
    "        y = xp.xnorpopcountmatmul((x + 1) / 2, (W + 1) / 2)\n",
    "    else:\n",
    "        y = np.matmul(x, W)\n",
    "    if T is not None:\n",
    "        y = multithreshold(y, T)\n",
    "        if act == DataType.BIPOLAR:\n",
    "            # binary to bipolar\n",
    "            y = 2 * y - 1\n",
    "        else:\n",
    "            # signed offset\n",
    "            y += act.min()\n",
    "    oshape = model.get_tensor_shape(\"outp\")\n",
    "    y_expected = y.reshape(oshape)\n",
    "    # execute model\n",
    "    y_produced = oxe.execute_onnx(model, input_dict)[\"outp\"]\n",
    "\n",
    "    y_produced = y_produced.reshape(y_expected.shape)\n",
    "\n",
    "    assert (y_produced == y_expected).all(), \"cppsim failed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394b2cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ipytest\n",
    "\n",
    "# mem_mode: const or decoupled\n",
    "@pytest.mark.parametrize(\"mem_mode\", [\"const\"])\n",
    "# activation: None or DataType\n",
    "@pytest.mark.parametrize(\"act\", [DataType.BIPOLAR, DataType.INT2, DataType.INT4])\n",
    "# weight datatype\n",
    "@pytest.mark.parametrize(\"wdt\", [DataType.BIPOLAR, DataType.INT2, DataType.INT4])\n",
    "# input datatype\n",
    "@pytest.mark.parametrize(\"idt\", [DataType.BIPOLAR, DataType.INT2, DataType.INT4])\n",
    "# neuron folding, -1 is maximum possible\n",
    "@pytest.mark.parametrize(\"nf\", [-1, 2, 1])\n",
    "# synapse folding, -1 is maximum possible\n",
    "@pytest.mark.parametrize(\"sf\", [-1, 2, 1])\n",
    "# HLS matrix width (input features)\n",
    "@pytest.mark.parametrize(\"mw\", [8])\n",
    "# HLS matrix height (output features)\n",
    "@pytest.mark.parametrize(\"mh\", [8])\n",
    "@pytest.mark.slow\n",
    "@pytest.mark.vivado\n",
    "\n",
    "def test_fpgadataflow_fclayer_rtlsim(mem_mode, idt, wdt, act, nf, sf, mw, mh):\n",
    "    if nf == -1:\n",
    "        nf = mh\n",
    "    if sf == -1:\n",
    "        sf = mw\n",
    "    pe = mh // nf\n",
    "    simd = mw // sf\n",
    "    assert mh % pe == 0\n",
    "    assert mw % sf == 0\n",
    "    # generate weights\n",
    "    W = gen_finn_dt_tensor(wdt, (mw, mh))\n",
    "    # generate input data\n",
    "    x = gen_finn_dt_tensor(idt, (1, mw))\n",
    "    if act is None:\n",
    "        # no activation, produce accumulators\n",
    "        T = None\n",
    "        tdt = None\n",
    "        if wdt == DataType.BIPOLAR and idt == DataType.BIPOLAR:\n",
    "            odt = DataType.UINT32\n",
    "        else:\n",
    "            odt = DataType.INT32\n",
    "    else:\n",
    "        odt = act\n",
    "        (min, max) = calculate_signed_dot_prod_range(idt, wdt, mw)\n",
    "        n_steps = act.get_num_possible_values() - 1\n",
    "        T = np.random.randint(min, max - 1, (mh, n_steps)).astype(np.float32)\n",
    "        # provide non-decreasing thresholds\n",
    "        T = np.sort(T, axis=1)\n",
    "        # generate thresholds for activation\n",
    "        if wdt == DataType.BIPOLAR and idt == DataType.BIPOLAR:\n",
    "            tdt = DataType.UINT32\n",
    "            # bias thresholds to be positive\n",
    "            T = np.ceil((T + mw) / 2)\n",
    "            assert (T >= 0).all()\n",
    "        else:\n",
    "            tdt = DataType.INT32\n",
    "    model = make_single_fclayer_modelwrapper(W, pe, simd, wdt, idt, odt, T, tdt)\n",
    "    for node in model.graph.node:\n",
    "        # lookup op_type in registry of CustomOps\n",
    "        inst = getCustomOp(node)\n",
    "        inst.set_nodeattr(\"mem_mode\", mem_mode)\n",
    "\n",
    "    # prepare input data\n",
    "    input_dict = prepare_inputs(x, idt, wdt)\n",
    "    if wdt == DataType.BIPOLAR and idt == DataType.BIPOLAR:\n",
    "        # convert inputs to binary and use xnorpopcountmatmul\n",
    "        y = xp.xnorpopcountmatmul((x + 1) / 2, (W + 1) / 2)\n",
    "    else:\n",
    "        y = np.matmul(x, W)\n",
    "    if T is not None:\n",
    "        y = multithreshold(y, T)\n",
    "        if act == DataType.BIPOLAR:\n",
    "            # binary to bipolar\n",
    "            y = 2 * y - 1\n",
    "        else:\n",
    "            # signed offset\n",
    "            y += act.min()\n",
    "    oshape = model.get_tensor_shape(\"outp\")\n",
    "    y_expected = y.reshape(oshape)\n",
    "    # TODO split up into several dependent tests -- need to check how this\n",
    "    # works for parametrized tests...\n",
    "    model = model.transform(SetExecMode(\"rtlsim\"))\n",
    "    model = model.transform(GiveUniqueNodeNames())\n",
    "    model = model.transform(PrepareIP(\"xc7z020clg400-1\", 5))\n",
    "    model = model.transform(HLSSynthIP())\n",
    "    model = model.transform(PrepareRTLSim())\n",
    "    y_produced = oxe.execute_onnx(model, input_dict)[\"outp\"]\n",
    "    assert (y_produced.reshape(y_expected.shape) == y_expected).all(), \"rtlsim failed\"\n",
    "\n",
    "    hls_synt_res_est = model.analysis(hls_synth_res_estimation)\n",
    "    assert \"StreamingFCLayer_Batch_0\" in hls_synt_res_est\n",
    "\n",
    "    node = model.get_nodes_by_op_type(\"StreamingFCLayer_Batch\")[0]\n",
    "    inst = getCustomOp(node)\n",
    "    cycles_rtlsim = inst.get_nodeattr(\"cycles_rtlsim\")\n",
    "    exp_cycles_dict = model.analysis(exp_cycles_per_layer)\n",
    "    exp_cycles = exp_cycles_dict[node.name]\n",
    "    assert np.isclose(exp_cycles, cycles_rtlsim, atol=15)\n",
    "    assert exp_cycles != 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01270a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fpgadataflow_fclayer_synth(mem_mode, idt, wdt, act, nf, sf, mw, mh):\n",
    "    if nf == -1:\n",
    "        nf = mh\n",
    "    if sf == -1:\n",
    "        sf = mw\n",
    "    pe = mh // nf\n",
    "    simd = mw // sf\n",
    "    assert mh % pe == 0\n",
    "    assert mw % sf == 0\n",
    "    # generate weights\n",
    "    W = gen_finn_dt_tensor(wdt, (mw, mh))\n",
    "    # generate input data\n",
    "    x = gen_finn_dt_tensor(idt, (1, mw))\n",
    "    if act is None:\n",
    "        # no activation, produce accumulators\n",
    "        T = None\n",
    "        tdt = None\n",
    "        if wdt == DataType.BIPOLAR and idt == DataType.BIPOLAR:\n",
    "            odt = DataType.UINT32\n",
    "        else:\n",
    "            odt = DataType.INT32\n",
    "    else:\n",
    "        odt = act\n",
    "        (min, max) = calculate_signed_dot_prod_range(idt, wdt, mw)\n",
    "        n_steps = act.get_num_possible_values() - 1\n",
    "        T = np.random.randint(min, max - 1, (mh, n_steps)).astype(np.float32)\n",
    "        # provide non-decreasing thresholds\n",
    "        T = np.sort(T, axis=1)\n",
    "        # generate thresholds for activation\n",
    "        if wdt == DataType.BIPOLAR and idt == DataType.BIPOLAR:\n",
    "            tdt = DataType.UINT32\n",
    "            # bias thresholds to be positive\n",
    "            T = np.ceil((T + mw) / 2)\n",
    "            assert (T >= 0).all()\n",
    "        else:\n",
    "            tdt = DataType.INT32\n",
    "            \n",
    "    model = make_single_fclayer_modelwrapper(W, pe, simd, wdt, idt, odt, T, tdt)\n",
    "    for node in model.graph.node:\n",
    "        # lookup op_type in registry of CustomOps\n",
    "        inst = getCustomOp(node)\n",
    "        inst.set_nodeattr(\"mem_mode\", mem_mode)\n",
    "\n",
    "    # prepare input data\n",
    "    input_dict = prepare_inputs(x, idt, wdt)\n",
    "    if wdt == DataType.BIPOLAR and idt == DataType.BIPOLAR:\n",
    "        # convert inputs to binary and use xnorpopcountmatmul\n",
    "        y = xp.xnorpopcountmatmul((x + 1) / 2, (W + 1) / 2)\n",
    "    else:\n",
    "        y = np.matmul(x, W)\n",
    "    if T is not None:\n",
    "        y = multithreshold(y, T)\n",
    "        if act == DataType.BIPOLAR:\n",
    "            # binary to bipolar\n",
    "            y = 2 * y - 1\n",
    "        else:\n",
    "            # signed offset\n",
    "            y += act.min()\n",
    "    oshape = model.get_tensor_shape(\"outp\")\n",
    "    y_expected = y.reshape(oshape)\n",
    "    # TODO split up into several dependent tests -- need to check how this\n",
    "    # works for parametrized tests...\n",
    " \n",
    "    model = model.transform(SetExecMode(\"rtlsim\"))\n",
    "    model = model.transform(GiveUniqueNodeNames())\n",
    "    model = model.transform(PrepareIP(\"xc7z020clg400-1\", 10))\n",
    "    model = model.transform(HLSSynthIP())\n",
    "    model = model.transform(PrepareRTLSim())\n",
    "    y_produced = oxe.execute_onnx(model, input_dict)[\"outp\"]\n",
    "    assert (y_produced.reshape(y_expected.shape) == y_expected).all(), \"rtlsim failed\"\n",
    "    \n",
    "\n",
    "    node = model.get_nodes_by_op_type(\"StreamingFCLayer_Batch\")[0]   \n",
    "    inst = getCustomOp(node)\n",
    "    inst.set_nodeattr(\"inFIFODepth\", 8)\n",
    "    inst.set_nodeattr(\"outFIFODepth\", 8)\n",
    "    #print(inst.get_nodeattr_types())\n",
    "    #cycles_rtlsim = inst.get_nodeattr(\"cycles_rtlsim\")\n",
    "    \n",
    "\n",
    "    model.save(build_dir+\"/tfc_experiment.onnx\")\n",
    "    showInNetron(build_dir+\"/tfc_experiment.onnx\")\n",
    "    \n",
    "    #analysis\n",
    "    exp_cycles_dict = model.analysis(exp_cycles_per_layer)\n",
    "    exp_cycles = exp_cycles_dict[node.name]\n",
    "    assert exp_cycles != 0\n",
    "    print('Estimation of execution cycles is:', exp_cycles)\n",
    "    \n",
    "    res_util_dict = model.analysis(res_estimation)\n",
    "    #res = res_util_dict[node.name]\n",
    "    print('The Estimation of Resource Utilization is', res_util_dict)\n",
    "    \n",
    "       \n",
    "    hls_synt_res_est = model.analysis(hls_synth_res_estimation)\n",
    "    assert \"StreamingFCLayer_Batch_0\" in hls_synt_res_est\n",
    "    print('Estimation of HLS Synth is', hls_synt_res_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666a2996",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fpgadataflow_fclayer_synth('const', DataType.INT4, DataType.INT4, DataType.INT4, 2, 1, 8, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad821023",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(build_dir + \"/tfc_experiment.onnx\")\n",
    "pynq_board = \"Pynq-Z1\"\n",
    "fpga_part = pynq_part_map[pynq_board]\n",
    "target_clk_ns = 10\n",
    "model = model.transform(ZynqBuild(platform = pynq_board, period_ns = target_clk_ns))\n",
    "model.save(build_dir+\"/tfc_synthesis.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f34ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "showInNetron(build_dir+\"/tfc_synthesis.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f3b838",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = ModelWrapper(build_dir + \"/tfc_synthesis.onnx\")\n",
    "sdp_node_middle = getCustomOp(model.graph.node[1])\n",
    "postsynth_layers = sdp_node_middle.get_nodeattr(\"model\")\n",
    "\n",
    "showInNetron(postsynth_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83314e64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model = ModelWrapper(postsynth_layers)\n",
    "model.model.metadata_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcba657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# set up the following values according to your own environment\n",
    "# FINN will use ssh to deploy and run the generated accelerator\n",
    "ip = os.getenv(\"PYNQ_IP\", \"192.168.31.175\")\n",
    "username = os.getenv(\"PYNQ_USERNAME\", \"xilinx\")\n",
    "password = os.getenv(\"PYNQ_PASSWORD\", \"xilinx\")\n",
    "port = os.getenv(\"PYNQ_PORT\", 22)\n",
    "target_dir = os.getenv(\"PYNQ_TARGET_DIR\", \"/home/xilinx/finn_tfc_end2end_example\")\n",
    "# set up ssh options to only allow publickey authentication\n",
    "options = \"-o PreferredAuthentications=publickey -o PasswordAuthentication=no\"\n",
    "\n",
    "# test access to PYNQ board\n",
    "! ssh {options} {username}@{ip} -p {port} cat /var/run/motd.dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed692582",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.transformation.fpgadataflow.make_deployment import DeployToPYNQ\n",
    "\n",
    "model = model.transform(DeployToPYNQ(ip, port, username, password, target_dir))\n",
    "model.save(build_dir + \"/tfc_experiment_deploy_index18.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e2336b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dir_pynq = target_dir + \"/\" + model.get_metadata_prop(\"pynq_deployment_dir\").split(\"/\")[-1]\n",
    "target_dir_pynq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a216289e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = ModelWrapper(build_dir + \"/tfc_synthesis.onnx\")\n",
    "synth_res = model.analysis(post_synth_res)\n",
    "print(\"Post Synthesis Resource Utilization is\",synth_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c78964",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.core.throughput_test import throughput_test_remote\n",
    "\n",
    "res = throughput_test_remote(model, 1)\n",
    "print(\"Network metrics:\")\n",
    "for key in res:\n",
    "    print(str(key) + \": \" + str(res[key]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
